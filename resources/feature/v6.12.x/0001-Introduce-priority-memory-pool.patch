From cbccbd4f37c84085a6e09ba72ffd043cc3b5bd07 Mon Sep 17 00:00:00 2001
From: Vernon Yang <vernon2gm@gmail.com>
Date: Sun, 26 Jan 2025 10:58:42 +0800
Subject: [PATCH] Introduce priority memory pool

This feature is priority memory buffer pool support. Such pools are
mostly used for hight priority thread to allocate memory.

Signed-off-by: Vernon Yang <vernon2gm@gmail.com>
---
 include/linux/priority_mempool.h |  73 ++++++++++++
 include/linux/vm_event_item.h    |   6 +
 mm/Kconfig                       |   6 +
 mm/Makefile                      |   1 +
 mm/page_alloc.c                  |   5 +
 mm/priority_mempool.c            | 185 +++++++++++++++++++++++++++++++
 mm/vmstat.c                      |   5 +
 7 files changed, 281 insertions(+)
 create mode 100644 include/linux/priority_mempool.h
 create mode 100644 mm/priority_mempool.c

diff --git a/include/linux/priority_mempool.h b/include/linux/priority_mempool.h
new file mode 100644
index 000000000000..501b94d7606b
--- /dev/null
+++ b/include/linux/priority_mempool.h
@@ -0,0 +1,73 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * priority memory buffer pool support
+ */
+#ifndef _LINUX_PMEMPOOL_H
+#define _LINUX_PMEMPOOL_H
+
+#include <linux/mm_types.h>
+
+#ifdef CONFIG_PMEMPOOL
+
+struct page *__priority_mempool_alloc(gfp_t gfp_mask, unsigned int order,
+							bool prealloc);
+void priority_mempool_free(struct page *page, unsigned int order);
+
+static inline struct page *priority_mempool_alloc_noprof(gfp_t gfp_mask,
+							unsigned int order)
+{
+	return __priority_mempool_alloc(gfp_mask, order, false);
+}
+
+static inline struct page *priority_mempool_prealloc_noprof(gfp_t gfp_mask,
+							unsigned int order)
+{
+	return __priority_mempool_alloc(gfp_mask, order, true);
+}
+
+#define priority_mempool_alloc(...)					\
+	alloc_hooks(priority_mempool_alloc_noprof(__VA_ARGS__))
+
+#define priority_mempool_prealloc(...)					\
+	alloc_hooks(priority_mempool_prealloc_noprof(__VA_ARGS__))
+
+#else
+
+static inline struct page *__priority_mempool_alloc(gfp_t gfp_mask,
+						    unsigned int order,
+						    bool prealloc)
+{
+	return NULL;
+}
+
+static inline void priority_mempool_free(struct page *page, unsigned int order)
+{
+}
+
+static inline struct page *priority_mempool_alloc_noprof(gfp_t gfp_mask,
+							unsigned int order)
+{
+	return NULL;
+}
+
+static inline struct page *priority_mempool_prealloc_noprof(gfp_t gfp_mask,
+							unsigned int order)
+{
+	return NULL;
+}
+
+static inline struct page *priority_mempool_alloc(gfp_t gfp_mask,
+						  unsigned int order)
+{
+	return NULL;
+}
+
+static inline struct page *priority_mempool_prealloc(gfp_t gfp_mask,
+						     unsigned int order)
+{
+	return NULL;
+}
+
+#endif
+
+#endif /* _LINUX_PMEMPOOL_H */
diff --git a/include/linux/vm_event_item.h b/include/linux/vm_event_item.h
index f70d0958095c..b87d7475faa3 100644
--- a/include/linux/vm_event_item.h
+++ b/include/linux/vm_event_item.h
@@ -49,6 +49,12 @@ enum vm_event_item { PGPGIN, PGPGOUT, PSWPIN, PSWPOUT,
 		PGSCAN_FILE,
 		PGSTEAL_ANON,
 		PGSTEAL_FILE,
+
+#ifdef CONFIG_PMEMPOOL
+		PGPOOL_SUCCESS,
+		PGPOOL_FAILED,
+#endif
+
 #ifdef CONFIG_NUMA
 		PGSCAN_ZONE_RECLAIM_SUCCESS,
 		PGSCAN_ZONE_RECLAIM_FAILED,
diff --git a/mm/Kconfig b/mm/Kconfig
index 84000b016808..510ec8f0653e 100644
--- a/mm/Kconfig
+++ b/mm/Kconfig
@@ -1301,6 +1301,12 @@ config ARCH_HAS_USER_SHADOW_STACK
 	  The architecture has hardware support for userspace shadow call
           stacks (eg, x86 CET, arm64 GCS or RISC-V Zicfiss).
 
+config PMEMPOOL
+	bool "priority memory pool"
+	help
+	  This feature is priority memory buffer pool support. Such pools are
+	  mostly used for hight priority thread to allocate memory.
+
 source "mm/damon/Kconfig"
 
 endmenu
diff --git a/mm/Makefile b/mm/Makefile
index dba52bb0da8a..56a7f1ca070d 100644
--- a/mm/Makefile
+++ b/mm/Makefile
@@ -146,3 +146,4 @@ obj-$(CONFIG_GENERIC_IOREMAP) += ioremap.o
 obj-$(CONFIG_SHRINKER_DEBUG) += shrinker_debug.o
 obj-$(CONFIG_EXECMEM) += execmem.o
 obj-$(CONFIG_TMPFS_QUOTA) += shmem_quota.o
+obj-$(CONFIG_PMEMPOOL) += priority_mempool.o
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 01eab25edf89..2b3571a9919c 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -55,6 +55,7 @@
 #include <linux/delayacct.h>
 #include <linux/cacheinfo.h>
 #include <linux/pgalloc_tag.h>
+#include <linux/priority_mempool.h>
 #include <asm/div64.h>
 #include "internal.h"
 #include "shuffle.h"
@@ -4378,6 +4379,10 @@ __alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,
 	if (current->flags & PF_MEMALLOC)
 		goto nopage;
 
+	page = priority_mempool_prealloc(gfp_mask, order);
+	if (page)
+		goto got_pg;
+
 	/* Try direct reclaim and then allocating */
 	page = __alloc_pages_direct_reclaim(gfp_mask, order, alloc_flags, ac,
 							&did_some_progress);
diff --git a/mm/priority_mempool.c b/mm/priority_mempool.c
new file mode 100644
index 000000000000..b95cc54cf47d
--- /dev/null
+++ b/mm/priority_mempool.c
@@ -0,0 +1,185 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ *  linux/mm/priority_mempool.c
+ *
+ *  priority memory buffer pool support. Such pools are mostly used
+ *  for hight priority thread to allocate memory.
+ *
+ *  started by Vernon Yang, Copyright (C) 2025
+ */
+
+#include <linux/module.h>
+#include <linux/kthread.h>
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+#include <linux/sched/rt.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#include <linux/vmstat.h>
+#include <linux/mempool.h>
+#include <linux/priority_mempool.h>
+
+#define MEMPOOL_MIN_NR		1024
+#define MEMPOOL_MAX_ORDER	1
+#define PMEMPOOL_NR		(MEMPOOL_MAX_ORDER + 1)
+
+static mempool_t *pmempool[PMEMPOOL_NR];
+
+static struct task_struct *kpmempoold;
+static struct wait_queue_head wq;
+static int refill;
+
+struct dentry *pmempool_debugfs_dir;
+
+static bool is_high_priority(struct task_struct *task)
+{
+	if (rt_or_dl_task_policy(task))
+		return true;
+
+	return false;
+}
+
+static mempool_t *look_for_mempool(unsigned int order)
+{
+	if (order > MEMPOOL_MAX_ORDER)
+		return NULL;
+
+	return pmempool[order];
+}
+
+struct page *__priority_mempool_alloc(gfp_t gfp_mask, unsigned int order,
+							bool prealloc)
+{
+	mempool_t *pool;
+	struct page *page;
+
+	/* skip kpmempoold thread */
+	if (current->pid == kpmempoold->pid)
+		return NULL;
+
+	if (!is_high_priority(current))
+		return NULL;
+
+	pool = look_for_mempool(order);
+	if (pool == NULL)
+		return NULL;
+
+	if (prealloc)
+		page = mempool_alloc_preallocated(pool);
+	else
+		page = mempool_alloc_noprof(pool, gfp_mask);
+
+	if (!mempool_is_saturated(pool) && (refill == 0)) {
+		refill = 1;
+		wake_up_interruptible(&wq);
+	}
+
+	count_vm_event(page ? PGPOOL_SUCCESS : PGPOOL_FAILED);
+
+	return page;
+}
+EXPORT_SYMBOL(__priority_mempool_alloc);
+
+void priority_mempool_free(struct page *page, unsigned int order)
+{
+	mempool_t *pool;
+
+	pool = look_for_mempool(order);
+	if (pool == NULL)
+		return;
+
+	mempool_free(page, pool);
+}
+EXPORT_SYMBOL(priority_mempool_free);
+
+static int pmempool_refill(void *arg)
+{
+	mempool_t *pool;
+	void *element;
+	int i;
+
+	while (!kthread_should_stop()) {
+		if (wait_event_interruptible(wq, refill == 1))
+			continue;
+
+		for (i = 0; i < PMEMPOOL_NR; i++) {
+			pool = pmempool[i];
+			while (!mempool_is_saturated(pool)) {
+				element = pool->alloc(GFP_KERNEL, pool->pool_data);
+				if (unlikely(element == NULL)) {
+					msleep(10);
+					continue;
+				}
+
+				mempool_free(element, pool);
+			}
+		}
+
+		refill = 0;
+	}
+
+	return 0;
+}
+
+static int stat_show(struct seq_file *s, void *data)
+{
+	mempool_t *pool;
+	int order;
+	int i;
+
+	for (i = 0; i < PMEMPOOL_NR; i++) {
+		pool = pmempool[i];
+		if (pool == NULL)
+			continue;
+
+		order = (int)(long)pool->pool_data;
+
+		seq_printf(s, "order %d\n", order);
+		seq_printf(s, "  min_nr   %d\n", pool->min_nr);
+		seq_printf(s, "  curr_nr  %d\n", pool->curr_nr);
+	}
+
+	return 0;
+}
+DEFINE_SHOW_ATTRIBUTE(stat);
+
+static int __init priority_mempool_init(void)
+{
+	int i;
+
+	for (i = 0; i < PMEMPOOL_NR; i++)
+		pmempool[i] = mempool_create_page_pool(MEMPOOL_MIN_NR, i);
+
+	init_waitqueue_head(&wq);
+	kpmempoold = kthread_run(pmempool_refill, NULL, "kpmempoold");
+	if (IS_ERR(kpmempoold)) {
+		pr_err("Failed to start kpmempooldï¼Œret=%ld\n",
+					PTR_ERR(kpmempoold));
+	}
+
+	if (debugfs_initialized()) {
+		pmempool_debugfs_dir = debugfs_create_dir("pmempool", NULL);
+		debugfs_create_file("stat", 0444, pmempool_debugfs_dir, NULL,
+				    &stat_fops);
+	}
+
+	return 0;
+}
+
+static void __exit priority_mempool_exit(void)
+{
+	int i;
+
+	debugfs_remove(pmempool_debugfs_dir);
+	kthread_stop(kpmempoold);
+
+	for (i = 0; i < PMEMPOOL_NR; i++)
+		mempool_destroy(pmempool[i]);
+}
+
+module_init(priority_mempool_init);
+module_exit(priority_mempool_exit);
+
+MODULE_AUTHOR("Vernon Yang <vernon2gm@gmail.com>");
+MODULE_DESCRIPTION("PRIORITY MEMPOOL MODULE");
+MODULE_LICENSE("GPL");
diff --git a/mm/vmstat.c b/mm/vmstat.c
index 16bfe1c694dd..a00fa86bd09f 100644
--- a/mm/vmstat.c
+++ b/mm/vmstat.c
@@ -1316,6 +1316,11 @@ const char * const vmstat_text[] = {
 	"pgsteal_anon",
 	"pgsteal_file",
 
+#ifdef CONFIG_PMEMPOOL
+	"pgpool_success",
+	"pgpool_failed",
+#endif
+
 #ifdef CONFIG_NUMA
 	"zone_reclaim_success",
 	"zone_reclaim_failed",
-- 
2.34.1

