From afce0c0dd9e932d3e2e3d0a1cbac30bef51ecb2e Mon Sep 17 00:00:00 2001
From: Vernon Yang <vernon2gm@gmail.com>
Date: Sun, 26 Jan 2025 10:58:42 +0800
Subject: [PATCH] Introduce priority memory pool

This feature is priority memory buffer pool support. Such pools are
mostly used for hight priority thread to allocate memory.

Signed-off-by: Vernon Yang <vernon2gm@gmail.com>
---
 include/linux/priority_mempool.h |  74 ++++++++++
 include/linux/vm_event_item.h    |   9 ++
 mm/Kconfig                       |   5 +
 mm/Makefile                      |   1 +
 mm/page_alloc.c                  |   5 +
 mm/priority_mempool.c            | 237 +++++++++++++++++++++++++++++++
 mm/vmstat.c                      |   8 ++
 7 files changed, 339 insertions(+)
 create mode 100644 include/linux/priority_mempool.h
 create mode 100644 mm/priority_mempool.c

diff --git a/include/linux/priority_mempool.h b/include/linux/priority_mempool.h
new file mode 100644
index 000000000000..58965f0dd9fc
--- /dev/null
+++ b/include/linux/priority_mempool.h
@@ -0,0 +1,74 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * priority memory buffer pool support
+ */
+#ifndef _LINUX_PMEMPOOL_H
+#define _LINUX_PMEMPOOL_H
+
+#include <linux/mm_types.h>
+#include "internal.h"
+
+#ifdef CONFIG_PMEMPOOL
+
+struct page *__priority_mempool_alloc(gfp_t gfp_mask, unsigned int order,
+							bool prealloc);
+void priority_mempool_free(struct page *page, unsigned int order);
+
+static inline struct page *priority_mempool_alloc_noprof(gfp_t gfp_mask,
+							unsigned int order)
+{
+	return __priority_mempool_alloc(gfp_mask, order, false);
+}
+
+static inline struct page *priority_mempool_prealloc_noprof(gfp_t gfp_mask,
+							unsigned int order)
+{
+	return __priority_mempool_alloc(gfp_mask, order, true);
+}
+
+#define priority_mempool_alloc(...)					\
+	alloc_hooks(priority_mempool_alloc_noprof(__VA_ARGS__))
+
+#define priority_mempool_prealloc(...)					\
+	alloc_hooks(priority_mempool_prealloc_noprof(__VA_ARGS__))
+
+#else
+
+static inline struct page *__priority_mempool_alloc(gfp_t gfp_mask,
+						    unsigned int order,
+						    bool prealloc)
+{
+	return NULL;
+}
+
+static inline void priority_mempool_free(struct page *page, unsigned int order)
+{
+}
+
+static inline struct page *priority_mempool_alloc_noprof(gfp_t gfp_mask,
+							unsigned int order)
+{
+	return NULL;
+}
+
+static inline struct page *priority_mempool_prealloc_noprof(gfp_t gfp_mask,
+							unsigned int order)
+{
+	return NULL;
+}
+
+static inline struct page *priority_mempool_alloc(gfp_t gfp_mask,
+						  unsigned int order)
+{
+	return NULL;
+}
+
+static inline struct page *priority_mempool_prealloc(gfp_t gfp_mask,
+						     unsigned int order)
+{
+	return NULL;
+}
+
+#endif
+
+#endif /* _LINUX_PMEMPOOL_H */
diff --git a/include/linux/vm_event_item.h b/include/linux/vm_event_item.h
index f70d0958095c..79eb7add6abe 100644
--- a/include/linux/vm_event_item.h
+++ b/include/linux/vm_event_item.h
@@ -49,6 +49,15 @@ enum vm_event_item { PGPGIN, PGPGOUT, PSWPIN, PSWPOUT,
 		PGSCAN_FILE,
 		PGSTEAL_ANON,
 		PGSTEAL_FILE,
+
+#ifdef CONFIG_PMEMPOOL
+		PGPOOL_SUCCESS,
+		PGPOOL_FAILED,
+		PGPOOL_REFILL,
+		PGPOOL_REFILL_FAILED,
+		PGPOOL_REFILL_WAKEUP,
+#endif
+
 #ifdef CONFIG_NUMA
 		PGSCAN_ZONE_RECLAIM_SUCCESS,
 		PGSCAN_ZONE_RECLAIM_FAILED,
diff --git a/mm/Kconfig b/mm/Kconfig
index 1b501db06417..ff7f47e1dce7 100644
--- a/mm/Kconfig
+++ b/mm/Kconfig
@@ -1358,6 +1358,11 @@ config PT_RECLAIM
 
 	  Note: now only empty user PTE page table pages will be reclaimed.
 
+config PMEMPOOL
+	bool "priority memory pool"
+	help
+	  This feature is priority memory buffer pool support. Such pools are
+	  mostly used for hight priority thread to allocate memory.
 
 source "mm/damon/Kconfig"
 
diff --git a/mm/Makefile b/mm/Makefile
index 850386a67b3e..4e4e5ff18008 100644
--- a/mm/Makefile
+++ b/mm/Makefile
@@ -147,3 +147,4 @@ obj-$(CONFIG_SHRINKER_DEBUG) += shrinker_debug.o
 obj-$(CONFIG_EXECMEM) += execmem.o
 obj-$(CONFIG_TMPFS_QUOTA) += shmem_quota.o
 obj-$(CONFIG_PT_RECLAIM) += pt_reclaim.o
+obj-$(CONFIG_PMEMPOOL) += priority_mempool.o
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 579789600a3c..9db703d774e8 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -55,6 +55,7 @@
 #include <linux/delayacct.h>
 #include <linux/cacheinfo.h>
 #include <linux/pgalloc_tag.h>
+#include <linux/priority_mempool.h>
 #include <asm/div64.h>
 #include "internal.h"
 #include "shuffle.h"
@@ -4378,6 +4379,10 @@ __alloc_pages_slowpath(gfp_t gfp_mask, unsigned int order,
 	if (current->flags & PF_MEMALLOC)
 		goto nopage;
 
+	page = priority_mempool_prealloc(gfp_mask, order);
+	if (page)
+		goto got_pg;
+
 	/* Try direct reclaim and then allocating */
 	page = __alloc_pages_direct_reclaim(gfp_mask, order, alloc_flags, ac,
 							&did_some_progress);
diff --git a/mm/priority_mempool.c b/mm/priority_mempool.c
new file mode 100644
index 000000000000..1d23fee11f0d
--- /dev/null
+++ b/mm/priority_mempool.c
@@ -0,0 +1,237 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ *  linux/mm/priority_mempool.c
+ *
+ *  priority memory buffer pool support. Such pools are mostly used
+ *  for hight priority thread to allocate memory.
+ *
+ *  started by Vernon Yang, Copyright (C) 2025
+ */
+
+#include <linux/module.h>
+#include <linux/kthread.h>
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+#include <linux/sched/rt.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#include <linux/vmstat.h>
+#include <linux/mempool.h>
+#include <linux/priority_mempool.h>
+
+#define MEMPOOL_MIN_NR			1024
+#define MEMPOOL_MAX_MIGRATE_TYPES	MIGRATE_PCPTYPES
+#define MEMPOOL_MAX_ORDER		(PAGE_ALLOC_COSTLY_ORDER + 1)
+
+static mempool_t *pmempool[MEMPOOL_MAX_MIGRATE_TYPES][MEMPOOL_MAX_ORDER];
+
+#define for_each_pmempool(pool, mtype, order)				\
+	for (mtype = 0; mtype < MEMPOOL_MAX_MIGRATE_TYPES; mtype++)	\
+		for (order = 0, pool = look_for_mempool(mtype, order);	\
+				order < MEMPOOL_MAX_ORDER;		\
+				pool = look_for_mempool(mtype, ++order))
+
+static struct task_struct *kpmempoold;
+static struct wait_queue_head wq;
+static int refill;
+
+static struct dentry *pmempool_debugfs_dir;
+static bool enabled;
+
+static inline gfp_t migratetype_gfp(int migratetype)
+{
+	gfp_t gfp_mask = __GFP_COMP | __GFP_NOMEMALLOC | __GFP_KSWAPD_RECLAIM |
+			__GFP_NOWARN | __GFP_NORETRY | __GFP_ZERO;
+
+	if (migratetype == MIGRATE_MOVABLE)
+		gfp_mask |= __GFP_MOVABLE;
+	else if (migratetype == MIGRATE_RECLAIMABLE)
+		gfp_mask |= __GFP_RECLAIMABLE;
+
+	return gfp_mask;
+}
+
+static inline mempool_t *look_for_mempool(int mtype, int order)
+{
+	if (mtype >= MEMPOOL_MAX_MIGRATE_TYPES ||
+	    order >= MEMPOOL_MAX_ORDER)
+		return NULL;
+
+	return pmempool[mtype][order];
+}
+
+struct page *__priority_mempool_alloc(gfp_t gfp_mask, unsigned int order,
+							bool prealloc)
+{
+	mempool_t *pool;
+	struct page *page;
+
+	if (unlikely(!enabled))
+		return NULL;
+
+	/* skip kpmempoold thread */
+	if (current->pid == kpmempoold->pid)
+		return NULL;
+
+	pool = look_for_mempool(gfp_migratetype(gfp_mask), order);
+	if (pool == NULL)
+		return NULL;
+
+	if (prealloc)
+		page = mempool_alloc_preallocated(pool);
+	else
+		page = mempool_alloc_noprof(pool, gfp_mask);
+
+	if (page) {
+		kmsan_free_page(page, order);
+		set_page_count(page, 0);
+	}
+
+	if (!mempool_is_saturated(pool) && (refill == 0)) {
+		refill = 1;
+		wake_up_interruptible(&wq);
+		count_vm_event(PGPOOL_REFILL_WAKEUP);
+	}
+
+	count_vm_event(page ? PGPOOL_SUCCESS : PGPOOL_FAILED);
+
+	return page;
+}
+EXPORT_SYMBOL(__priority_mempool_alloc);
+
+void priority_mempool_free(struct page *page, unsigned int order)
+{
+	mempool_t *pool;
+
+	if (unlikely(!enabled))
+		return;
+
+	pool = look_for_mempool(get_pageblock_migratetype(page), order);
+	if (pool == NULL)
+		return;
+
+	mempool_free(page, pool);
+}
+EXPORT_SYMBOL(priority_mempool_free);
+
+static int pmempool_refill(void *arg)
+{
+	mempool_t *pool;
+	gfp_t gfp_mask;
+	int mtype;
+	int order;
+	void *element;
+
+	while (!kthread_should_stop()) {
+		if (wait_event_interruptible(wq, refill == 1))
+			continue;
+
+		for_each_pmempool(pool, mtype, order) {
+			while (!mempool_is_saturated(pool)) {
+				gfp_mask = migratetype_gfp(mtype);
+				element = pool->alloc(gfp_mask, (void *)(long)order);
+				if (unlikely(element == NULL)) {
+					count_vm_event(PGPOOL_REFILL_FAILED);
+					msleep(10);
+					continue;
+				}
+
+				mempool_free(element, pool);
+				count_vm_event(PGPOOL_REFILL);
+			}
+		}
+
+		refill = 0;
+	}
+
+	return 0;
+}
+
+static int stat_show(struct seq_file *s, void *data)
+{
+	mempool_t *pool = NULL;
+	int mtype;
+	int order;
+
+	for_each_pmempool(pool, mtype, order) {
+		if (pool == NULL)
+			continue;
+
+		seq_printf(s, "%s order %d\n", migratetype_names[mtype], order);
+		seq_printf(s, "  min_nr   %d\n", pool->min_nr);
+		seq_printf(s, "  curr_nr  %d\n", pool->curr_nr);
+	}
+
+	return 0;
+}
+DEFINE_SHOW_ATTRIBUTE(stat);
+
+static int enabled_show(struct seq_file *s, void *data)
+{
+	seq_printf(s, "%d\n", enabled);
+
+	return 0;
+}
+
+static ssize_t enabled_write(struct file *f, const char __user *ubuf, size_t len,
+			     loff_t *offset)
+{
+	if (kstrtobool_from_user(ubuf, len, &enabled))
+		return -EINVAL;
+
+	return len;
+}
+DEFINE_SHOW_STORE_ATTRIBUTE(enabled);
+
+static int __init priority_mempool_init(void)
+{
+	mempool_t *pool = NULL;
+	int mtype;
+	int order;
+
+	for_each_pmempool(pool, mtype, order) {
+		pmempool[mtype][order] = mempool_create_node(MEMPOOL_MIN_NR,
+							mempool_alloc_pages,
+							mempool_free_pages,
+							(void *)(long)order,
+							migratetype_gfp(mtype),
+							NUMA_NO_NODE);
+	}
+
+	init_waitqueue_head(&wq);
+	kpmempoold = kthread_run(pmempool_refill, NULL, "kpmempoold");
+	if (IS_ERR(kpmempoold)) {
+		pr_err("Failed to start kpmempooldï¼Œret=%ld\n",
+					PTR_ERR(kpmempoold));
+	}
+
+	if (debugfs_initialized()) {
+		pmempool_debugfs_dir = debugfs_create_dir("pmempool", NULL);
+		debugfs_create_file("stat", 0444, pmempool_debugfs_dir, NULL,
+				    &stat_fops);
+		debugfs_create_file("enabled", 0644, pmempool_debugfs_dir, NULL,
+				    &enabled_fops);
+	}
+
+	return 0;
+}
+
+static void __exit priority_mempool_exit(void)
+{
+	mempool_t *pool;
+	int mtype;
+	int order;
+
+	debugfs_remove(pmempool_debugfs_dir);
+	kthread_stop(kpmempoold);
+
+	for_each_pmempool(pool, mtype, order)
+		mempool_destroy(pool);
+}
+
+module_init(priority_mempool_init);
+module_exit(priority_mempool_exit);
+
+MODULE_AUTHOR("Vernon Yang <vernon2gm@gmail.com>");
+MODULE_DESCRIPTION("PRIORITY MEMPOOL MODULE");
+MODULE_LICENSE("GPL");
diff --git a/mm/vmstat.c b/mm/vmstat.c
index 16bfe1c694dd..e8a4a48bacfa 100644
--- a/mm/vmstat.c
+++ b/mm/vmstat.c
@@ -1316,6 +1316,14 @@ const char * const vmstat_text[] = {
 	"pgsteal_anon",
 	"pgsteal_file",
 
+#ifdef CONFIG_PMEMPOOL
+	"pgpool_success",
+	"pgpool_failed",
+	"pgpool_refill",
+	"pgpool_refill_failed",
+	"pgpool_refill_wakeup",
+#endif
+
 #ifdef CONFIG_NUMA
 	"zone_reclaim_success",
 	"zone_reclaim_failed",
-- 
2.34.1

